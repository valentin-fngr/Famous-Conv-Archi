{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import activations\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Residual blocks \n",
    "#Id function allows us to train a bigger network with the same layers.\n",
    "    #=> We put X, keep X + a residual block learning the changes on X\n",
    "    #=> Weights ---> 0 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "LABELS = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "HEIGHT = x_train.shape[1]\n",
    "WIDTH = x_train.shape[2]\n",
    "INPUT_SHAPE = (HEIGHT, WIDTH, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's build the model ! \n",
    "\n",
    "#Resnet Block ! \n",
    "def residual_block(x, kernel, nb_filters, reduce=False): \n",
    "\n",
    "    result = x\n",
    "    if reduce: \n",
    "        #Reduce shape => stride = 2  + 1x1\n",
    "        #First conv if reduce \n",
    "        conv_result = tf.keras.layers.Conv2D(\n",
    "            strides=2, \n",
    "            kernel_size=1,\n",
    "            filters=nb_filters,\n",
    "            padding=\"SAME\", \n",
    "            input_shape=x.shape[1::]\n",
    "        )(result)\n",
    "        #batch norm after each convolution \n",
    "        batch_norm_result = tf.keras.layers.BatchNormalization()(conv_result)\n",
    "        result = tf.keras.layers.ReLU(batch_norm_result)\n",
    "    #Anyways run the first imposed conv\n",
    "    conv_result = tf.keras.layers.Conv2D(\n",
    "        strides=1, \n",
    "        kernel_size=kernel,\n",
    "        filters=nb_filters,\n",
    "        padding=\"SAME\", \n",
    "        input_shape=x.shape[1::]\n",
    "    )(result)\n",
    "    #Batch norm and activation (RELU)\n",
    "    batch_norm_result = tf.keras.layers.BatchNormalization()(conv_result)\n",
    "    result = tf.keras.layers.ReLU(batch_norm_result)\n",
    "    #Second imposed convolution \n",
    "    conv_result2 = tf.keras.layers.Conv2D(\n",
    "        strides=1, \n",
    "        kernel_size=kernel, \n",
    "        filters=nb_filters, \n",
    "        padding=\"SAME\", \n",
    "        input_shape=x.shape[1::]\n",
    "    )(result)\n",
    "    #batch norm after each convolution \n",
    "    batch_norm_result2 = tf.keras.layers.BatchNormalization()(conv_result2)\n",
    "    #F(x) + x\n",
    "    block_result = batch_norm_result2 + x\n",
    "    #Using relu on the addition\n",
    "    activation_block_result = tf.keras.layers.ReLU(block_result)\n",
    "    return activation_block_result     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO \n",
    "# filters = [] => idx i = block i \n",
    "# nbr_filters = []\n",
    "# res_block_nbr = [3, 4, 6, 3]\n",
    "def ResNet(x, filters, nbr_filters, res_block_nbr): \n",
    "    \n",
    "    #start resnet HERE : \n",
    "        #7x7, 64 filters, stride = 2, padding = \"same\"\n",
    "        #3x3 max pool, stride = 2\n",
    "    \n",
    "    #We assume we are in an 18 layer mindset => only 2 blocks of convolution by \n",
    "    result = x\n",
    "    for step in range(len(filters)): \n",
    "        #Processing each convs\n",
    "        #First Block = Reducing dimensions\n",
    "        result = residual_block(\n",
    "                    x=result, \n",
    "                    nb_filters=nbr_filters[step], \n",
    "                    kernel=filters[step], \n",
    "                    reduce=True\n",
    "                )\n",
    "        #Other blocks\n",
    "        for i in range(1,nbr_block_nbr): \n",
    "            result = residual_block(\n",
    "                        x=result, \n",
    "                        nb_filters=nbr_filters[step], \n",
    "                        kernel=filters[step], \n",
    "                        reduce=False\n",
    "                    )\n",
    "    #Average pooling \n",
    "    result_final_pool = tf.keras.layers.AveragePooling2D()(result)\n",
    "    #returining probabilities\n",
    "    final_fc = tf.keras.layers.Dense(units=1000, activation=\"softmax\")(result_final_pool)\n",
    "    return final_fc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
