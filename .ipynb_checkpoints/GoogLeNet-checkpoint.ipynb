{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build GoogleNet \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This architecture uses the Inception module, We will explain this module :)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Important notes about the first reading : </h3>\n",
    "<br>\n",
    "<ul> \n",
    "    <li>\n",
    "        <i>\" 1 × 1 convolutions have dual purpose: most critically, they are used mainly as dimension reduction modules to remove computational bottlenecks \"</i>\n",
    "    </li>\n",
    "    <li>\n",
    "        <i>The most straightforward way of improving the performance of deep neural networks is by increasing their size</i>\n",
    "    </li>\n",
    "    <li>\n",
    "        <i>Bigger size typically means a larger number of parameters, which makes the enlarged network more\n",
    "            prone to overfitting</i>\n",
    "    </li>\n",
    "    <li>\n",
    "        <i>Another drawback of uniformly increased network size is the dramatically increased use of computational resources</i>\n",
    "    </li>\n",
    "    <li>\n",
    "        <i> current incarnations of the Inception architecture are restricted to filter sizes 1×1,\n",
    "3×3 and 5×5, however this decision was based more on convenience rather than necessity</i>\n",
    "    <li>\n",
    "        <img src=\"inception.PNG\"/>\n",
    "    </li>\n",
    "    <li>\n",
    "        <i>Besides being used as reductions, they also include the use of rectified linear activation which makes them dual-purpose</i>\n",
    "    </li>\n",
    "    <li>\n",
    "        <i>occasional max-pooling layers with stride 2 to halve the resolution of the grid</i>\n",
    "    </li>\n",
    "    <li>\n",
    "        <img src=\"GoogleNetSummary.PNG\">\n",
    "    </li>\n",
    "    <li>\n",
    "        <i>\n",
    "            We have also\n",
    "used a deeper and wider Inception network, the quality of which was slightly inferior, but adding it\n",
    "to the ensemble seemed to improve the results marginally.\n",
    "        </i>\n",
    "    </li>\n",
    "</ul>\n",
    "\n",
    "<h2>Topology and training</h2>\n",
    "\n",
    "<ul>\n",
    "    <li><i>size of the receptive field in our network is 224×224 taking RGB color channels with mean subtraction</i></li>\n",
    "    <li><i>“#3×3 reduce” and “#5×5 reduce” stands for the number of 1×1 filters in the reduction</i></li>\n",
    "    <li><i>The network is 22 layers deep when counting only layers with\n",
    "        parameters (or 27 layers if we also count pooling)</i></li>\n",
    "    <li><i>The overall number of layers (independent building blocks) used for the construction of the network is about 100.</i></li>\n",
    "    <li><i>however the use of dropout remained\n",
    "        essential even after removing the fully connected layers</i></li>\n",
    "    <li><i>By adding auxiliary classifiers connected to\n",
    "these intermediate layers, we would expect to encourage discrimination in the lower stages in the\n",
    "classifier, increase the gradient signal that gets propagated back, and provide additional regularization</i></li>\n",
    "    <img src=\"extra_classifier.PNG\">\n",
    "    <img src=\"extra_classifier2.PNG\">\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
